{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0369ea7f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìú Licence d'utilisation\n",
    "\n",
    "Ce document est prot√©g√© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "üîí **Aucune modification ni r√©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- üë§ Auteur : Christie Vassilian  \n",
    "- üì• T√©l√©chargement autoris√© uniquement √† usage p√©dagogique personnel  \n",
    "- üö´ R√©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBJ 1 ‚Äî O√π l‚ÄôIA regarde ?\n",
    "### Initiation √† l'explicabilit√© en vision par ordinateur\n",
    "\n",
    "**Objectif :** comprendre comment une IA \"regarde\" une image et quelles zones influencent sa d√©cision.\n",
    "\n",
    "Dans ce premier TP, nous allons :\n",
    "- afficher une image et demander √† un mod√®le ce qu‚Äôil voit ;\n",
    "- modifier l‚Äôimage petit morceau par petit morceau (occlusion) ;\n",
    "- calculer l‚Äôimportance des pixels √† l‚Äôaide d‚Äôun gradient simple (saliency) ;\n",
    "- comparer les diff√©rentes explications ;\n",
    "- r√©fl√©chir √† la notion m√™me d‚Äô‚Äúexplicabilit√©‚Äù.\n",
    "\n",
    "Aucun outil XAI externe : tout est fait √† la main, pour comprendre les bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : placer une image adapt√©e dans le m√™me dossier, par exemple 'image_chien.jpg'\n",
    "img_path = \"image_chien.jpg\"  # √† adapter\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_input = np.expand_dims(img_array.copy(), axis=0)\n",
    "img_preprocessed = preprocess_input(img_input)\n",
    "\n",
    "plt.imshow(img_array.astype(\"uint8\"))\n",
    "plt.title(\"Image originale\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 1  \n",
    "Selon toi, **quelles zones** de cette image l'IA va-t-elle regarder pour d√©cider ce que c'est ?  \n",
    "Explique ton intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobilenet_v2.MobileNetV2(weights=\"imagenet\")\n",
    "preds = model.predict(img_preprocessed)\n",
    "decode_predictions(preds, top=3)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questions 2‚Äì3  \n",
    "2. Le mod√®le a-t-il raison ? Pourquoi ?  \n",
    "3. D‚Äôapr√®s toi, **o√π** regarde-t-il pour prendre sa d√©cision ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusion_map(model, img_array, patch_size=30, stride=10):\n",
    "    h, w, _ = img_array.shape\n",
    "    heatmap = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    base_pred = model.predict(preprocess_input(np.expand_dims(img_array, 0)))[0]\n",
    "    base_class = np.argmax(base_pred)\n",
    "\n",
    "    for y in range(0, h - patch_size, stride):\n",
    "        for x in range(0, w - patch_size, stride):\n",
    "            occluded = img_array.copy()\n",
    "            occluded[y:y+patch_size, x:x+patch_size] = 0\n",
    "\n",
    "            pred = model.predict(preprocess_input(np.expand_dims(occluded, 0)))[0]\n",
    "            drop = float(base_pred[base_class] - pred[base_class])\n",
    "            heatmap[y:y+patch_size, x:x+patch_size] = drop\n",
    "\n",
    "    heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "    return heatmap_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_occ = occlusion_map(model, img_array, patch_size=30, stride=10)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_array.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Image originale\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(heatmap_occ, cmap=\"jet\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Occlusion ‚Äî zones importantes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questions 4‚Äì6  \n",
    "4. Quand on cache une petite zone, comment la pr√©diction change-t-elle ?  \n",
    "5. Quelles zones semblent les plus importantes pour le mod√®le ?  \n",
    "6. L‚ÄôIA regarde-t-elle les m√™mes zones que toi ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tf = tf.convert_to_tensor(img_preprocessed, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(img_tf)\n",
    "    preds_tf = model(img_tf)\n",
    "    top_index = tf.argmax(preds_tf[0])\n",
    "\n",
    "grads = tape.gradient(preds_tf[0, top_index], img_tf)[0]\n",
    "saliency = np.max(np.abs(grads.numpy()), axis=-1)\n",
    "\n",
    "saliency_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_array.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Image originale\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(saliency_norm, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Saliency Map (gradient)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questions 7‚Äì9  \n",
    "7. Les pixels les plus brillants correspondent-ils aux zones importantes ?  \n",
    "8. L‚Äôexplication est-elle ‚Äúpropre‚Äù ou bruit√©e ?  \n",
    "9. Quelles diff√©rences vois-tu entre l‚Äôocclusion et la saliency ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothgrad(model, img_preprocessed, n_samples=20, noise=0.2):\n",
    "    grads_list = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        noisy = img_preprocessed + noise * np.random.normal(size=img_preprocessed.shape)\n",
    "        noisy_tf = tf.convert_to_tensor(noisy, dtype=tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(noisy_tf)\n",
    "            preds_tf = model(noisy_tf)\n",
    "            top_index = tf.argmax(preds_tf[0])\n",
    "\n",
    "        g = tape.gradient(preds_tf[0, top_index], noisy_tf)[0].numpy()\n",
    "        grads_list.append(np.max(np.abs(g), axis=-1))\n",
    "\n",
    "    avg = np.mean(np.stack(grads_list, axis=0), axis=0)\n",
    "    avg_norm = (avg - avg.min()) / (avg.max() - avg.min() + 1e-8)\n",
    "    return avg_norm\n",
    "\n",
    "smooth = smoothgrad(model, img_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(saliency_norm, cmap='inferno')\n",
    "plt.title(\"Saliency brute\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(smooth, cmap='inferno')\n",
    "plt.title(\"SmoothGrad\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(heatmap_occ, cmap='jet')\n",
    "plt.title(\"Occlusion\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questions 10‚Äì12  \n",
    "10. SmoothGrad est-il plus lisible que la saliency brute ? Pourquoi ?  \n",
    "11. Les zones importantes sont-elles coh√©rentes entre les 3 m√©thodes ?  \n",
    "12. Laquelle te para√Æt la plus intuitive ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Synth√®se ‚Äî Qu'avons-nous appris ?\n",
    "\n",
    "- Une IA ne regarde **pas toute l‚Äôimage** : elle se concentre sur quelques zones cl√©s.  \n",
    "- L‚Äôocclusion permet de voir **o√π** une zone influence la d√©cision.  \n",
    "- Les saliency maps montrent **quels pixels** ont le plus d‚Äôimpact.  \n",
    "- SmoothGrad am√©liore la lisibilit√©.  \n",
    "- Ces explications nous aident √† comprendre *comment* l‚ÄôIA prend ses d√©cisions.\n",
    "\n",
    "### ‚ùì Question finale  \n",
    "En une phrase : **pour toi, qu‚Äôest-ce qu‚Äôune ‚Äúbonne explication‚Äù d‚Äôun mod√®le IA ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf341361",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìú Licence d'utilisation\n",
    "\n",
    "Ce document est prot√©g√© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "üîí **Aucune modification ni r√©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- üë§ Auteur : Christie Vassilian  \n",
    "- üì• T√©l√©chargement autoris√© uniquement √† usage p√©dagogique personnel  \n",
    "- üö´ R√©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdc25f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
