{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de540c19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸ“œ Licence d'utilisation\n",
    "\n",
    "Ce document est protÃ©gÃ© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "ðŸ”’ **Aucune modification ni rÃ©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- ðŸ‘¤ Auteur : Christie Vassilian  \n",
    "- ðŸ“¥ TÃ©lÃ©chargement autorisÃ© uniquement Ã  usage pÃ©dagogique personnel  \n",
    "- ðŸš« RÃ©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2ca6f",
   "metadata": {},
   "source": [
    "Mise en place :\n",
    "- mettre une image de travail : 'sample.jpg'\n",
    "- choisir un environement de travail virtuel avec cv2\n",
    "- raccourci utile de VSC : CTRL+ALT+P Pyhton (choix du bon python) - CTRL+ALT+P Clear All Output (Mets toutes les cellules Ã  zÃ©ro)\n",
    "\n",
    "Bonne ballade au pays des filtres !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019e665",
   "metadata": {},
   "source": [
    "\n",
    "# Initiation aux filtres avec OpenCV â€” v2 (NBJ)\n",
    "\n",
    "Objectif : dÃ©couvrir les filtres et opÃ©rations de base en **traitement d'image** avec **OpenCV** (convolution, lissage,\n",
    "dÃ©tection de contours, rehaussement, contrastes, seuillage, effets crÃ©atifs).\n",
    "\n",
    "> Conseils :  \n",
    "> - ExÃ©cute les cellules dans l'ordre.  \n",
    "> - Remplace le `path_img` par une image de ton choix.  \n",
    "> - Appuie sur **q** pour fermer les fenÃªtres `cv2.imshow`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1574c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- Utilitaires --------\n",
    "\n",
    "def imshow_cv(title, img):\n",
    "    \"\"\"Affiche une image avec cv2.imshow et gÃ¨re la fermeture par 'q'.\"\"\"\n",
    "    cv2.imshow(title, img)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def imshow_plt(img_bgr, title=\"Image (RGB via matplotlib)\"):\n",
    "    \"\"\"Affiche une image BGR (OpenCV) en RGB via matplotlib (utile si imshow ne marche pas).\"\"\"\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def read_image(path_img):\n",
    "    img = cv2.imread(str(path_img))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image introuvable : {path_img}\\nPlace une image dans ce chemin, ou modifie path_img.\")\n",
    "    return img\n",
    "\n",
    "def stack_h(*imgs):\n",
    "    \"\"\"Empile horizontalement des images de mÃªmes dimensions.\"\"\"\n",
    "    return np.hstack(imgs)\n",
    "\n",
    "def stack_v(*imgs):\n",
    "    \"\"\"Empile verticalement des images de mÃªmes dimensions.\"\"\"\n",
    "    return np.vstack(imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21426b4b",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Charger une image\n",
    "\n",
    "Modifie `path_img` si nÃ©cessaire. Les deux fonctions d'affichage sont fournies :  \n",
    "- `imshow_cv` (fenÃªtre OpenCV, fermer avec **q**),  \n",
    "- `imshow_plt` (affichage inline Notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Chemin de l'image ---\n",
    "# Exemple: path_img = 'data/lena.png'  (Ã  adapter)\n",
    "path_img = 'image/sample.jpg'   # <- remplace par ton image\n",
    "\n",
    "# Charger\n",
    "img = read_image(path_img)\n",
    "print(img.shape, img.dtype)\n",
    "\n",
    "# Afficher en RGB via matplotlib (pratique dans les notebooks)\n",
    "imshow_plt(img, title=\"Image originale (RGB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee722bc",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Convolution : noyaux 3Ã—3\n",
    "\n",
    "On applique `cv2.filter2D` avec diffÃ©rents noyaux (identitÃ©, flou boÃ®te, sharpen, Prewitt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kern_identity = np.array([[0,0,0],\n",
    "                          [0,1,0],\n",
    "                          [0,0,0]], dtype=np.float32)\n",
    "\n",
    "kern_box = (1/9.0) * np.ones((3,3), dtype=np.float32)\n",
    "\n",
    "kern_sharpen = np.array([[0,-1,0],\n",
    "                         [-1,5,-1],\n",
    "                         [0,-1,0]], dtype=np.float32)\n",
    "\n",
    "# Prewitt\n",
    "kern_prewitt_x = np.array([[-1,0,1],\n",
    "                           [-1,0,1],\n",
    "                           [-1,0,1]], dtype=np.float32)\n",
    "kern_prewitt_y = np.array([[-1,-1,-1],\n",
    "                           [ 0, 0, 0],\n",
    "                           [ 1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "out_identity = cv2.filter2D(img, -1, kern_identity)\n",
    "out_box      = cv2.filter2D(img, -1, kern_box)\n",
    "out_sharp    = cv2.filter2D(img, -1, kern_sharpen)\n",
    "out_pwx      = cv2.filter2D(img, -1, kern_prewitt_x)\n",
    "out_pwy      = cv2.filter2D(img, -1, kern_prewitt_y)\n",
    "\n",
    "# AperÃ§u matplotlib (Ã©vite d'ouvrir 5 fenÃªtres)\n",
    "row1 = stack_h(out_identity, out_box, out_sharp)\n",
    "row2 = stack_h(out_pwx, out_pwy, img)\n",
    "grid = stack_v(row1, row2)\n",
    "imshow_plt(grid, title=\"Convolution 3x3: IdentitÃ© | Box | Sharpen / Prewitt X | Prewitt Y | Originale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b5322",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Lissages (anti-bruit)\n",
    "\n",
    "Comparer : **Box**, **Gaussian**, **Median**, **Bilateral** (prÃ©serve mieux les bords).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "box = cv2.blur(img, (7,7))\n",
    "gauss = cv2.GaussianBlur(img, (7,7), 1.5)\n",
    "median = cv2.medianBlur(img, 7)\n",
    "bilat = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "row = stack_h(box, gauss, median, bilat)\n",
    "imshow_plt(row, title=\"Box | Gaussian | Median | Bilateral\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312a6c1",
   "metadata": {},
   "source": [
    "\n",
    "## 4) DÃ©rivÃ©es (Sobel, Laplacien) et magnitude du gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sx = cv2.Sobel(gray, cv2.CV_16S, 1, 0, ksize=3)\n",
    "sy = cv2.Sobel(gray, cv2.CV_16S, 0, 1, ksize=3)\n",
    "sobel_x = cv2.convertScaleAbs(sx)\n",
    "sobel_y = cv2.convertScaleAbs(sy)\n",
    "\n",
    "lap = cv2.Laplacian(gray, cv2.CV_16S, ksize=3)\n",
    "lap = cv2.convertScaleAbs(lap)\n",
    "\n",
    "# Magnitude\n",
    "mag = np.sqrt(sx.astype(np.float32)**2 + sy.astype(np.float32)**2)\n",
    "mag = np.clip((mag / mag.max())*255, 0, 255).astype(np.uint8)\n",
    "\n",
    "trip = stack_h(cv2.cvtColor(sobel_x, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(sobel_y, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(lap, cv2.COLOR_GRAY2BGR))\n",
    "imshow_plt(trip, title=\"Sobel X | Sobel Y | Laplacien\")\n",
    "imshow_plt(cv2.cvtColor(mag, cv2.COLOR_GRAY2BGR), title=\"Magnitude du gradient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebeaaed",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Contours Canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, threshold1=100, threshold2=200)\n",
    "imshow_plt(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), title=\"Canny (100/200)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4db5dd",
   "metadata": {},
   "source": [
    "\n",
    "## 6) NettetÃ© : *Unsharp mask*\n",
    "\n",
    "Plus souple qu'un simple noyau sharpen 3Ã—3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sigma = 2.0\n",
    "alpha = 1.5  # gain\n",
    "blur = cv2.GaussianBlur(img, (0,0), sigmaX=sigma)\n",
    "unsharp = cv2.addWeighted(img, alpha, blur, -(alpha-1.0), 0)\n",
    "imshow_plt(unsharp, title=f\"Unsharp mask (sigma={sigma}, alpha={alpha})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85572e45",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Effet *Emboss* (relief)\n",
    "\n",
    "Noyau 3Ã—3 classique, avec recentrage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kern_emboss = np.array([[-2,-1,0],\n",
    "                        [-1, 1,1],\n",
    "                        [ 0, 1,2]], dtype=np.float32)\n",
    "emb = cv2.filter2D(img, -1, kern_emboss)\n",
    "emb = cv2.add(emb, 128)  # recentrer\n",
    "imshow_plt(emb, title=\"Emboss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72664ace",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Contraste local (CLAHE)\n",
    "\n",
    "Sur le canal **L** dans l'espace **LAB** pour Ã©viter les dÃ©rives de couleur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "L, A, B = cv2.split(lab)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "L2 = clahe.apply(L)\n",
    "lab2 = cv2.merge([L2, A, B])\n",
    "clahe_bgr = cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "row = stack_h(img, clahe_bgr)\n",
    "imshow_plt(row, title=\"Originale | CLAHE (LAB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba1fef",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Seuillage : fixe, Otsu, adaptatif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# binaire fixe\n",
    "_, th = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Otsu\n",
    "_, th_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Adaptatif\n",
    "th_adp_mean = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                    cv2.THRESH_BINARY, blockSize=21, C=5)\n",
    "th_adp_gauss = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, blockSize=21, C=5)\n",
    "\n",
    "row1 = stack_h(cv2.cvtColor(th, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(th_otsu, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(th_adp_mean, cv2.COLOR_GRAY2BGR))\n",
    "row2 = stack_h(cv2.cvtColor(th_adp_gauss, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR),\n",
    "               img)\n",
    "grid = stack_v(row1, row2)\n",
    "imshow_plt(grid, title=\"Fixe | Otsu | Adaptatif Mean / Adaptatif Gauss | Gray | Originale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c662637",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Posterization (quantification des intensitÃ©s)\n",
    "\n",
    "RÃ©duction du nombre de niveaux (ex. 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "levels = 4\n",
    "step = 256 // levels\n",
    "poster = (img // step) * step\n",
    "row = stack_h(img, poster)\n",
    "imshow_plt(row, title=f\"Originale | Posterization ({levels} niveaux)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021cf2c",
   "metadata": {},
   "source": [
    "\n",
    "## 11) NÃ©gatif et SÃ©pia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9160f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neg = 255 - img\n",
    "\n",
    "sepia_kernel = np.array([[0.272, 0.534, 0.131],\n",
    "                         [0.349, 0.686, 0.168],\n",
    "                         [0.393, 0.769, 0.189]], dtype=np.float32)\n",
    "sepia = cv2.transform(img, sepia_kernel)\n",
    "sepia = np.clip(sepia, 0, 255).astype(np.uint8)\n",
    "\n",
    "row = stack_h(img, neg, sepia)\n",
    "imshow_plt(row, title=\"Originale | NÃ©gatif | SÃ©pia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa585d85",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Dominante par canal (idÃ©e : *argmax* par pixel)\n",
    "\n",
    "Pour chaque pixel, on garde uniquement le canal le plus fort (B, G ou R).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcdca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b, g, r = cv2.split(img)\n",
    "stack = np.stack([b, g, r], axis=-1)  # HÃ—WÃ—3\n",
    "argmax = np.argmax(stack, axis=-1)    # 0/1/2\n",
    "\n",
    "dom = np.zeros_like(img)\n",
    "dom[argmax==0] = [255, 0, 0]   # Bleu dominant -> Bleu pur\n",
    "dom[argmax==1] = [0, 255, 0]   # Vert dominant -> Vert pur\n",
    "dom[argmax==2] = [0, 0, 255]   # Rouge dominant -> Rouge pur\n",
    "\n",
    "row = stack_h(img, dom)\n",
    "imshow_plt(row, title=\"Originale | Dominante de canal (B/G/R)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d85166",
   "metadata": {},
   "source": [
    "\n",
    "## 13) (Bonus) Morphologie : Ã©rosion / dilatation\n",
    "\n",
    "Utile pour nettoyer des masques binaires (aprÃ¨s seuillage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b18a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "er = cv2.erode(th, kernel, iterations=1)\n",
    "di = cv2.dilate(th, kernel, iterations=1)\n",
    "op = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel)\n",
    "cl = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "row1 = stack_h(cv2.cvtColor(th, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(er, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(di, cv2.COLOR_GRAY2BGR))\n",
    "row2 = stack_h(cv2.cvtColor(op, cv2.COLOR_GRAY2BGR),\n",
    "               cv2.cvtColor(cl, cv2.COLOR_GRAY2BGR),\n",
    "               img)\n",
    "grid = stack_v(row1, row2)\n",
    "imshow_plt(grid, title=\"Binaire | Ã‰rosion | Dilatation / Ouverture | Fermeture | Originale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e247ff",
   "metadata": {},
   "source": [
    "\n",
    "## 14) Exercices (Ã  faire faire aux Ã©lÃ¨ves)\n",
    "\n",
    "1. **Comparer** Median vs Gaussian sur une image avec bruit \"sel & poivre\".  \n",
    "2. **Composer** un pipeline : Bilateral â†’ Canny â†’ Dilatation (afin d'Ã©paissir les contours).  \n",
    "3. **Explorer** l'effet d'`alpha` et `sigma` sur l'Unsharp mask pour Ã©viter la sur-accentuation.  \n",
    "4. **CrÃ©er** un filtre emboss personnalisÃ© (noyau 3Ã—3) et commenter l'effet selon l'orientation.  \n",
    "5. **Tester** CLAHE : varier `clipLimit` et `tileGridSize` et expliquer le rÃ´le de chacun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87546eba",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**CrÃ©dits & remarques**  \n",
    "- Notebook pÃ©dagogique d'initiation (OpenCV).  \n",
    "- Pour des dÃ©monstrations en direct, tu peux remplacer certains `imshow_plt` par `imshow_cv` si tu prÃ©fÃ¨res des fenÃªtres natives.  \n",
    "- Fermer les fenÃªtres `cv2.imshow` avec **q**.\n",
    "\n",
    "Bon travail !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7d48e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸ“œ Licence d'utilisation\n",
    "\n",
    "Ce document est protÃ©gÃ© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "ðŸ”’ **Aucune modification ni rÃ©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- ðŸ‘¤ Auteur : Christie Vassilian  \n",
    "- ðŸ“¥ TÃ©lÃ©chargement autorisÃ© uniquement Ã  usage pÃ©dagogique personnel  \n",
    "- ðŸš« RÃ©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
