{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b76569",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìú Licence d'utilisation\n",
    "\n",
    "Ce document est prot√©g√© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "üîí **Aucune modification ni r√©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- üë§ Auteur : Christie Vassilian  \n",
    "- üì• T√©l√©chargement autoris√© uniquement √† usage p√©dagogique personnel  \n",
    "- üö´ R√©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce6e72",
   "metadata": {},
   "source": [
    "# YOLOv8 ‚Äì D√©couvrir la d√©tection d‚Äôobjets  \n",
    "_Notebook 1 : images, vid√©os, webcam_\n",
    "\n",
    "## Objectifs de la s√©ance\n",
    "\n",
    "Dans ce notebook, tu vas :\n",
    "\n",
    "1. Charger un **mod√®le YOLOv8 pr√©-entra√Æn√©** (d√©tection d‚Äôobjets).\n",
    "2. L‚Äôutiliser sur :\n",
    "   - une **image**,\n",
    "   - une **vid√©o**,\n",
    "   - la **webcam**.\n",
    "3. Lire et interpr√©ter les r√©sultats : **bo√Ætes**, **noms d‚Äôobjets**, **scores de confiance**.\n",
    "4. R√©fl√©chir aux **forces** et **limites** de ce type d‚ÄôIA.\n",
    "\n",
    "Des **questions** te guideront au fur et √† mesure. Prends le temps d‚Äôy r√©pondre dans ta copie ou dans un fichier texte √† part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881426",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Pr√©paration de l‚Äôenvironnement\n",
    "\n",
    "### 1.1. Installation des biblioth√®ques\n",
    "\n",
    "> ‚ö†Ô∏è Cette cellule est √† ex√©cuter **une seule fois** pour installer les biblioth√®ques n√©cessaires dans l‚Äôenvironnement.\n",
    "\n",
    "**Question 1 :**  \n",
    "Avant d‚Äôex√©cuter la cellule suivante, r√©ponds :  \n",
    "> √Ä ton avis, √† quoi servent les biblioth√®ques suivantes ?  \n",
    "> - `ultralytics`  \n",
    "> - `opencv-python` (`cv2`)  \n",
    "> - `matplotlib`\n",
    "\n",
    "*(Tu peux chercher rapidement sur Internet si besoin.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ä ex√©cuter une seule fois (ou √† commenter si d√©j√† install√©)\n",
    "!pip install -q ultralytics opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9151e9f",
   "metadata": {},
   "source": [
    "### 1.2. Import des biblioth√®ques\n",
    "\n",
    "On importe maintenant les modules Python dont on aura besoin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e987a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Versions :\")\n",
    "print(\" - OpenCV :\", cv2.__version__)\n",
    "print(\" - YOLO (ultralytics) import√© avec succ√®s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e8b13",
   "metadata": {},
   "source": [
    "### 1.3. Chargement du mod√®le YOLOv8\n",
    "\n",
    "Nous allons utiliser un mod√®le **pr√©-entra√Æn√©** : `yolov8n.pt` (‚Äún‚Äù pour *nano* ‚Üí mod√®le l√©ger, plus rapide).\n",
    "\n",
    "**Question 2 :**  \n",
    "Explique avec tes mots ce que signifie *¬´ mod√®le pr√©-entra√Æn√© ¬ª*.  \n",
    "En quoi est-ce diff√©rent d‚Äôun programme ‚Äúclassique‚Äù √©crit √† la main ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du mod√®le YOLOv8 \"nano\"\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(\"Mod√®le YOLOv8n charg√©.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366fd8b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. D√©tection d‚Äôobjets sur une image\n",
    "\n",
    "Nous allons d‚Äôabord tester YOLO sur une **image fixe**.\n",
    "\n",
    "> Pr√©pare dans le m√™me dossier que ce notebook un ou plusieurs fichiers image, par exemple :  \n",
    "> - `classe.jpg` (photo d‚Äôune salle de classe)  \n",
    "> - `rue.jpg` (photo d‚Äôune rue)  \n",
    "> - ou une autre image libre de droit.\n",
    "\n",
    "Nous allons commencer avec un nom de fichier par d√©faut que tu pourras modifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom du fichier image √† analyser\n",
    "# Modifie cette ligne avec le nom de ton image, par ex. \"classe.jpg\"\n",
    "image_path = Path(\"image_test.jpg\")\n",
    "\n",
    "if not image_path.is_file():\n",
    "    print(f\"‚ö†Ô∏è Fichier {image_path} introuvable. Place une image dans le dossier et change le nom ci-dessus.\")\n",
    "else:\n",
    "    print(f\"Image trouv√©e : {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_bgr(image_bgr, title=\"Image\"):\n",
    "    \"\"\"Affiche une image OpenCV (BGR) avec matplotlib (RGB).\"\"\"\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "if image_path.is_file():\n",
    "    img_bgr = cv2.imread(str(image_path))\n",
    "    if img_bgr is None:\n",
    "        print(\"Erreur de lecture de l'image.\")\n",
    "    else:\n",
    "        show_image_bgr(img_bgr, title=f\"Image originale : {image_path.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075c703",
   "metadata": {},
   "source": [
    "### 2.1. Lancer YOLO sur l‚Äôimage\n",
    "\n",
    "Nous allons maintenant appliquer le mod√®le YOLO √† l‚Äôimage et afficher le r√©sultat annot√©.\n",
    "\n",
    "**Question 3 :**  \n",
    "Avant de lancer la d√©tection, devine :  \n",
    "> Quels objets YOLO va-t-il probablement d√©tecter sur cette image ?  \n",
    "> Fais une petite liste de 3 √† 5 objets possibles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b09a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image_path.is_file():\n",
    "    # Lancement de la d√©tection\n",
    "    results = model(source=str(image_path))  # on donne directement le chemin du fichier\n",
    "    \n",
    "    # On r√©cup√®re le premier (et unique) r√©sultat\n",
    "    result = results[0]\n",
    "    \n",
    "    # Image annot√©e par YOLO (numpy array BGR)\n",
    "    annotated_frame = result.plot()\n",
    "    \n",
    "    show_image_bgr(annotated_frame, title=f\"Image annot√©e par YOLO : {image_path.name}\")\n",
    "else:\n",
    "    print(\"Aucune image √† analyser. V√©rifie le chemin du fichier plus haut.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ba6bf",
   "metadata": {},
   "source": [
    "### 2.2. Lire les r√©sultats (classes, scores‚Ä¶)\n",
    "\n",
    "YOLO ne donne pas seulement l‚Äôimage annot√©e. Il renvoie aussi une **liste d‚Äôobjets d√©tect√©s**, chaque objet √©tant d√©crit par :\n",
    "\n",
    "- sa **classe** (par ex. `person`, `car`, `bottle`),  \n",
    "- un **score de confiance** entre 0 et 1,  \n",
    "- ses coordonn√©es dans l‚Äôimage (rectangle).\n",
    "\n",
    "Nous allons afficher cette liste de mani√®re lisible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f063f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image_path.is_file():\n",
    "    result = results[0]\n",
    "    boxes = result.boxes  # bo√Ætes d√©tect√©es\n",
    "    \n",
    "    class_ids = boxes.cls.cpu().numpy().astype(int)\n",
    "    scores = boxes.conf.cpu().numpy()\n",
    "    xyxy = boxes.xyxy.cpu().numpy()  # coordonn√©es : x1, y1, x2, y2\n",
    "    \n",
    "    names = result.names  # dictionnaire id -> nom de classe\n",
    "    \n",
    "    print(\"Objets d√©tect√©s :\")\n",
    "    for cls_id, score, (x1, y1, x2, y2) in zip(class_ids, scores, xyxy):\n",
    "        label = names[int(cls_id)]\n",
    "        print(f\" - {label:10s} | score = {score:.2f} | bbox = ({int(x1)}, {int(y1)}, {int(x2)}, {int(y2)})\")\n",
    "else:\n",
    "    print(\"Aucun r√©sultat √† afficher.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981e142",
   "metadata": {},
   "source": [
    "**Question 4 :**  \n",
    "1. Combien d‚Äôobjets sont d√©tect√©s au total ?  \n",
    "2. Quels sont les **3 objets** avec les plus grands scores de confiance ?  \n",
    "3. Rep√®re un cas o√π l‚ÄôIA se trompe (ou semble se tromper). Est-ce un **faux positif** (objet d√©tect√© mais inexistant) ou un **faux n√©gatif** (objet r√©el non d√©tect√©) ?\n",
    "\n",
    "---\n",
    "\n",
    "## 3. YOLO sur une vid√©o\n",
    "\n",
    "Nous allons maintenant appliquer YOLO √† une **vid√©o**.\n",
    "\n",
    "> Pr√©pare un petit fichier vid√©o (par exemple `video_test.mp4`) dans le m√™me dossier que ce notebook.  \n",
    "> Id√©alement une vid√©o courte (quelques secondes) avec des personnes ou des objets en mouvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom du fichier vid√©o √† analyser\n",
    "video_path = Path(\"video_test.mp4\")\n",
    "\n",
    "if not video_path.is_file():\n",
    "    print(f\"‚ö†Ô∏è Fichier vid√©o {video_path} introuvable. Place une vid√©o dans le dossier et change le nom ci-dessus.\")\n",
    "else:\n",
    "    print(f\"Vid√©o trouv√©e : {video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202c949",
   "metadata": {},
   "source": [
    "### 3.1. Traitement de la vid√©o image par image\n",
    "\n",
    "Pour une vid√©o, YOLO fonctionne **image par image** :  \n",
    "chaque image (frame) est trait√©e comme une photo.\n",
    "\n",
    "Nous allons :  \n",
    "1. ouvrir la vid√©o,  \n",
    "2. lire les images une par une,  \n",
    "3. appliquer YOLO sur chaque image,  \n",
    "4. afficher **quelques images annot√©es** (une toutes les n images pour √©viter un affichage trop lourd).\n",
    "\n",
    "**Question 5 :**  \n",
    "√Ä ton avis, pourquoi la d√©tection est-elle plus difficile sur une vid√©o que sur une image fixe ?  \n",
    "Donne au moins **2 raisons** possibles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_path.is_file():\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur : impossible d'ouvrir la vid√©o.\")\n",
    "    else:\n",
    "        frame_count = 0\n",
    "        max_frames_to_show = 5   # nombre maximum d'images √† afficher dans le notebook\n",
    "        step = 10                # on affiche 1 image sur 10\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # fin de la vid√©o\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # On ne traite qu'une image sur 'step' pour l'affichage\n",
    "            if frame_count % step != 0:\n",
    "                continue\n",
    "            \n",
    "            # Application de YOLO sur la frame\n",
    "            results_video = model(source=frame, verbose=False)\n",
    "            result_v = results_video[0]\n",
    "            annotated = result_v.plot()  # image annot√©e\n",
    "            \n",
    "            show_image_bgr(annotated, title=f\"Frame {frame_count} annot√©e\")\n",
    "            \n",
    "            if frame_count // step >= max_frames_to_show:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        print(\"Traitement vid√©o termin√©.\")\n",
    "else:\n",
    "    print(\"Aucune vid√©o √† analyser. V√©rifie le chemin du fichier plus haut.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40905d80",
   "metadata": {},
   "source": [
    "**Question 6 :**  \n",
    "1. Sur les images annot√©es de la vid√©o, est-ce que YOLO d√©tecte **toujours** les m√™mes objets ?  \n",
    "2. Donne un exemple o√π un objet est d√©tect√© sur une image mais pas sur la suivante.  \n",
    "3. Explique pourquoi cela peut poser probl√®me si l‚Äôon veut **compter** les objets ou **suivre** une personne.\n",
    "\n",
    "> Remarque : YOLO **d√©tecte** les objets, mais ne fait pas de **suivi** (tracking) d‚Äôune image √† l‚Äôautre. Le suivi est un autre probl√®me √† part.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. YOLO en direct avec la webcam\n",
    "\n",
    "Derni√®re √©tape : faire tourner YOLO en **temps r√©el** sur la webcam.\n",
    "\n",
    "> ‚ö†Ô∏è Cette partie fonctionne surtout si tu ex√©cutes le notebook en local (par exemple avec Anaconda / VS Code), pas forc√©ment dans un environnement en ligne.\n",
    "\n",
    "Le principe :  \n",
    "1. Ouvrir la webcam (`cv2.VideoCapture(0)`),  \n",
    "2. Lire en boucle les images,  \n",
    "3. Appliquer YOLO sur chaque image,  \n",
    "4. Afficher le r√©sultat dans une fen√™tre,  \n",
    "5. Quitter quand l‚Äôutilisateur appuie sur la touche `q`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_webcam = False  # Passe √† True si tu es sur un ordinateur local avec webcam\n",
    "\n",
    "if use_webcam:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur : impossible d'ouvrir la webcam.\")\n",
    "    else:\n",
    "        print(\"Appuie sur 'q' dans la fen√™tre vid√©o pour quitter.\")\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Application de YOLO sur la frame\n",
    "            results_cam = model(source=frame, verbose=False)\n",
    "            result_c = results_cam[0]\n",
    "            annotated = result_c.plot()\n",
    "            \n",
    "            cv2.imshow(\"Webcam YOLOv8\", annotated)\n",
    "            \n",
    "            # Quitter avec la touche 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"La webcam n'est pas activ√©e. Passe use_webcam = True pour tester en local.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d6f0c",
   "metadata": {},
   "source": [
    "**Question 7 :**  \n",
    "En testant sur la webcam (si possible) :  \n",
    "1. Est-ce que YOLO te d√©tecte correctement comme `person` ?  \n",
    "2. Que se passe-t-il si tu te rapproches tr√®s pr√®s de la cam√©ra ? si tu t‚Äô√©loignes beaucoup ?  \n",
    "3. Que se passe-t-il si tu changes l‚Äô√©clairage (lumi√®re forte, lumi√®re faible) ?\n",
    "\n",
    "Explique en quelques phrases pourquoi la **qualit√© des images** (lumi√®re, angle, distance) est essentielle pour les performances de YOLO.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Bilan : que fait vraiment YOLO ?\n",
    "\n",
    "R√©ponds aux questions suivantes en t‚Äôappuyant sur ce que tu as observ√© :\n",
    "\n",
    "**Question 8 :**  \n",
    "1. YOLO ‚Äúcomprend-il‚Äù ce qu‚Äôil voit comme un humain, ou bien fait-il autre chose ?  \n",
    "2. Pourquoi peut-on dire qu‚Äôil **reconna√Æt des motifs statistiques** plut√¥t que des ‚Äúobjets‚Äù au sens humain ?\n",
    "\n",
    "**Question 9 :**  \n",
    "Donne un exemple de **situation r√©elle** o√π YOLO pourrait √™tre utile, et un exemple o√π son utilisation peut √™tre **dangereuse ou trompeuse** s‚Äôil se trompe (faux positifs ou faux n√©gatifs).\n",
    "\n",
    "**Question 10 :**  \n",
    "Propose une id√©e d‚Äôam√©lioration ou d‚Äôextension :  \n",
    "- Que voudrais-tu mesurer, compter ou analyser en plus ?  \n",
    "- Sur quelles images ou vid√©os aimerais-tu tester YOLO ?\n",
    "\n",
    "---\n",
    "\n",
    "Fin du Notebook 1 : tu as d√©couvert comment utiliser YOLOv8 sur des images, des vid√©os et la webcam, et tu as commenc√© √† r√©fl√©chir √† ses limites et √† ses usages possibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa2870",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìú Licence d'utilisation\n",
    "\n",
    "Ce document est prot√©g√© sous licence **Creative Commons BY-NC-ND 4.0 International**  \n",
    "üîí **Aucune modification ni r√©utilisation sans autorisation explicite de l'auteur.**\n",
    "\n",
    "- üë§ Auteur : Christie Vassilian  \n",
    "- üì• T√©l√©chargement autoris√© uniquement √† usage p√©dagogique personnel  \n",
    "- üö´ R√©utilisation commerciale ou modification interdite  \n",
    "\n",
    "[![Licence CC BY-NC-ND](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2796744",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
